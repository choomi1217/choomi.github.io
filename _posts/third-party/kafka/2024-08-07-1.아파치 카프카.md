---
title:  "[kafka] 아파치 카프카 애플리케이션 프로그래밍"

categories:
  - kafka
tags:
  - [kafka]

toc: true
toc_sticky: true

breadcrumbs: true

date: 2024-08-07
last_modified_at: 2024-08-07
---

# 아파치 카프카에 대하여

### 카프카란?
카프카는 소스 애플리케이션과 타깃 애플리케이션 사이의 의존도를 최소화 하기 위해 중앙 배치를 제공합니다.
소스 애플리케이션에서 생성되는 데이터는 어느 타깃으로 보낼지 고민하지 않고 카프카로 전송하면 됩니다.
카프카 내부에 데이터가 저장되는 파티션의 동작은 FIFO(First In First Out) 방식으로 동작합니다.
데이터를 카프카로 보내는 것이 **프로듀서** 이고, 카프카에서 데이터를 가져오는 것이 **컨슈머** 입니다.

### 카프카를 통해 전달할 수 있는 데이터 포맷
직렬화, 역직렬화를 통해 ByteArray로 통신하기 때문에 자바에서 선언 가능한 모든 객체를 지원합니다.
카프카 클라이언트에선 기본적으로 ByteArray, ByteBuffer, Double, Long, String 타입에 대응한 직렬화, 역직렬화를 제공합니다.
필요할 경우 카프카에서 제공하는 커스텀 직렬화, 역직렬화 클래스 (Serializer<T>, Deserializer<T>)를 사용할 수 있습니다.

### 빅데이터 파이프라인에서 카프카의 역할
빅데이터 파이프라인은 데이터를 수집, 저장, 처리, 분석하는 과정을 말합니다.
기업에서 실시간으로 저장하는 데이터의 양은 최소 TB에서 EB를 웃돕니다.
이런 대용량 데이터를 DB로 관리하는 것은 불가능에 가깝습니다.
빅데이터를 저장하고 활용하기 위해서는 생성되는 데이터를 전부 모으는 것이 중요한데, 이를 `데이터 레이크` 라고 합니다.

### 서비스에서 발생하는 데이터를 레이크에 모으려면 어떻게 해야 할까?  
단순하게 서비스에서 발생한 데이터를 레이크에 직접 end-to-end로 보내는 방식이 있습니다.
하지만, 서비스가 커지면 커질수록 데이터의 양이 많아지고, 파편회되고 복잡해지며 이 방식은 사용할 수 없어집니다.
데이터를 추출하고 변경, 적재하는 과정을 묶은 데이터 파이프라인을 구축해야 합니다.
이때 데이터 파이프라인을 안정적이고 확장성 높게 운영하기 위한 좋은 방법 중 하나가 바로 **아파치 카프카**입니다.


# 카프카가 왜 데이터 파이프라인으로 적합한가?

### 높은 처리량
카프카는 _프로듀서 -> 브로커_ 로 데이터를 보낼 때와 _브로커 -> 컨슈머_ 로 데이터를 받을 때  모두 묶어서 전송합니다.
많은 양의 데이터를 묶음 단위로 처리하는 배치로 빠르게 처리할 수 있기 때문에 대용량의 실시간 로그데이터를 처리하는 데에 적합합니다.
파티션 단위를 통해 동일 목적의 데이터를 여러 파티션에 분배하고 데이터를 병렬 처리할 수 있습니다.

### 확장성
데이터가 적을 때는 카프카 클러스터의 브로커를 최소한으로 운영하다가 데이터가 많아지면 브로커를 추가하여 확장할 수 있습니다.

### 영속성
카프카는 전송받은 데이터를 파일 시스템에 저장합니다.
카프카는 운영체제 레벨에서 파일 I/O 성능을 향상시키기 위해 페이지 캐시 영역을 메모리에 따로 생성하여 사용합니다.

### 고가용성
클러스터로 이루어진 카프카는 데이터의 복제를 통해 고가용성의 특징을 가지게 되었습니다.
3대 이상의 서버로 운영되는 카프카 클러스터는 일부 서버에 장애가 발생하더라도 무중단으로 서비스를 제공할 수 있습니다.
프로듀서로 전송받은 데이터를 여러 브로커에 복제하여 저장하고, 컨슈머는 복제된 데이터 중 하나를 가져와 사용합니다.
서버를 직접 운영하는 온프레미스 환경의 서버 랙 또는 퍼블릭 클라우드의 리전 단위 장애에도 안전하게 데이터를 복제할 수 있는 브로커 옵션들이 준비되어 있습니다.


